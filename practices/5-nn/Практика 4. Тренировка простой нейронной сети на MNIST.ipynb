{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вам нужно решить хрестоматийную задачу, которую как правило рассматривают во многих тьюториалах к фреймворкам для глубокого обучения и книгах.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет MNIST [отсюда](http://yann.lecun.com/exdb/mnist/) и поместите его в папку `data/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Постройте пайплайн обучения модели также как мы это делали в первой практике (разбиение на три множества 60/20/20)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выберите фреймворк который вам больше нравится:\n",
    "- [pytorch](https://pytorch.org/) - удобен тем, что граф вычислений по умолчанию строится \"на лету\"\n",
    "- [tensorflow](https://www.tensorflow.org/) - популярен, но до недавнего времени граф надо было задавать ahead of time, также он достаточно низкоуровневый\n",
    "- [keras](https://keras.io/) - удобная библиотека для построения нейронных сетей - может работать поверх tensorflow или theano\n",
    "\n",
    "Примеры:\n",
    "- Для keras: https://www.tensorflow.org/tutorials/keras/basic_classification \n",
    "- Для pytorch: https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/01-basics/feedforward_neural_network/main.py#L37-L49\n",
    "- Для tensorflow: https://www.tensorflow.org/guide/eager\n",
    "\n",
    "Обратите внимание что для этой задачи нет нужды уменьшать изображения как в первой практике.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите для задачи нейронную сеть с одним скрытым слоем на 100 нейронов и функцией активации ReLU. Для выходного слоя используйте softmax. В качестве оптимизатора используйте Adam. Какая точность у вас получилась?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь обучите нейронную сеть используя early stopping - следите за ошибкой на валидационном множестве и прекратите обучение, когда она перестанет расти на протяжении 20 эпох. Какая точность классификации у вас получилась теперь? Обратите внимание что early stopping уже реализован в фреймворках, его не нужно писать самому (кроме возможно tensorflow)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте подобрать лучшую архитектуру сети - добавьте слой, поменяйте количество нейронов - попробуйте Dropout. Поделитесь в тетрадке своим лучшим результатом."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
